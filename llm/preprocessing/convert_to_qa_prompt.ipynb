{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianporada/Research/envs/anaphora_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "from functools import partial\n",
    "\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_names = [\n",
    "    'conll2012_indiscrim_english_v4',\n",
    "    'gum_indiscrim_ontogum',\n",
    "    'arrau_indiscrim_default',\n",
    "    'gap_indiscrim_default',\n",
    "    'davis_pdp_indiscrim_default',\n",
    "    'preco_indiscrim_default',\n",
    "    'litbank_indiscrim_split_0',\n",
    "    'gum_indiscrim_original',\n",
    "    'phrase_detectives_indiscrim_default',\n",
    "    'mmc_indiscrim_mmc_en',\n",
    "    'davis_wsc_indiscrim_wsc273',\n",
    "    'superglue_wsc_indiscrim_default',\n",
    "    'dpr_indiscrim_default',\n",
    "    'knowref_60k_indiscrim_default',\n",
    "    'pronominal_winogrande_default'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_mapping(sentences, context_start, context_end):\n",
    "    local_to_global = {}\n",
    "    global_to_local = {}\n",
    "    t = 0\n",
    "    for s_i in range(context_start, context_end):\n",
    "        sentence = sentences[s_i]\n",
    "        for i in range(len(sentence[\"tokens\"])):\n",
    "            local_to_global[(s_i, i)] = t\n",
    "            global_to_local[t] = (s_i, i)\n",
    "            t += 1\n",
    "    return local_to_global, global_to_local\n",
    "\n",
    "\n",
    "def local_mention_to_global(local_to_global, mention):\n",
    "    sent, start, end = mention\n",
    "    return (\n",
    "                local_to_global[(sent, start)],\n",
    "                local_to_global[(sent, end)]\n",
    "            )\n",
    "\n",
    "\n",
    "def global_mention_to_local(global_to_local, mention):\n",
    "    start, end = mention\n",
    "    start_sent, start_tok = global_to_local[start]\n",
    "    end_sent, end_tok = global_to_local[end]\n",
    "    assert start_sent == end_sent and end_tok >= start_tok\n",
    "    return [start_sent, start_tok, end_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples(config_name, split, dataset, use_local_context, include_speaker):\n",
    "    examples = []\n",
    "    for ex in tqdm(dataset):\n",
    "        sentences = ex[\"sentences\"]\n",
    "\n",
    "        context_start = 0\n",
    "        context_end = len(sentences)\n",
    "\n",
    "        ex_id = ex[\"id\"]\n",
    "        psent, pstart, pend = ex[\"pronoun\"]\n",
    "        ex_id = str(ex[\"id\"]) + f\"_{psent}_{pstart}_{pend}\"\n",
    "        \n",
    "        if use_local_context:\n",
    "            context_start = ex[\"local_context_start\"]\n",
    "            context_end = ex[\"local_context_end\"]\n",
    "\n",
    "        local_to_global, global_to_local = get_token_mapping(sentences, context_start, context_end)\n",
    "        words = [[x[\"text\"] for x in s[\"tokens\"]] for s in sentences[context_start:context_end]]\n",
    "\n",
    "        speakers = None\n",
    "        if include_speaker:\n",
    "            speakers = [[s[\"speaker\"] if s[\"speaker\"] is not None else \"\"]*len(s[\"tokens\"])\n",
    "                        for s in sentences[context_start:context_end]]\n",
    "            speakers = [spk for s in speakers for spk in s]\n",
    "\n",
    "        lm_to_global = partial(local_mention_to_global, local_to_global)\n",
    "        mentions = [lm_to_global(ex[\"pronoun\"]),\n",
    "                    lm_to_global(ex[\"antecedents\"][0]),\n",
    "                    lm_to_global(ex[\"distractors\"][0])] # (start, end)\n",
    "        \n",
    "        # make sure each\n",
    "        instructions = \"Please carefully read the following passages. \" \\\n",
    "                \"For each passage, you must identify which noun the mention \" \\\n",
    "                \"marked in *bold* refers to.\\n\\n\"\n",
    "        \n",
    "        passage_words = [w for s in words for w in s]\n",
    "\n",
    "        global_antecedent = mentions[1]\n",
    "        expected_output_words = passage_words[global_antecedent[0] : global_antecedent[1] + 1]\n",
    "        expected_output = \" \".join(expected_output_words).lower()\n",
    "\n",
    "        global_distractor = mentions[2]\n",
    "        global_distractor_words = passage_words[global_distractor[0] : global_distractor[1] + 1]\n",
    "        negative_output = \" \".join(global_distractor_words).lower()\n",
    "\n",
    "        global_pronoun = mentions[0]\n",
    "        assert global_pronoun[0] == global_pronoun[1], \"Pronoun should be exactly one word\"\n",
    "        original_pronoun = passage_words[global_pronoun[0]]\n",
    "        passage_words[global_pronoun[0]] = f\"*{original_pronoun}*\" # add astericks around pronoun\n",
    "\n",
    "        # add square brackets to words in passage\n",
    "        passage_words[global_antecedent[0]] = f\"[{passage_words[global_antecedent[0]]}\"\n",
    "        passage_words[global_antecedent[1]] = f\"{passage_words[global_antecedent[1]]}]\"\n",
    "\n",
    "        passage_words[global_distractor[0]] = f\"[{passage_words[global_distractor[0]]}\"\n",
    "        passage_words[global_distractor[1]] = f\"{passage_words[global_distractor[1]]}]\"\n",
    "\n",
    "        if include_speaker:\n",
    "            last_speaker = None\n",
    "            passage = \"\"\n",
    "            for i, w in enumerate(passage_words):\n",
    "                curr_speaker = speakers[i] if speakers[i] else \"Anonymous\"\n",
    "                if curr_speaker != last_speaker:\n",
    "                    passage += f\"\\n\\n{curr_speaker}:\\n\"\n",
    "                    last_speaker = curr_speaker\n",
    "                passage += (\" \" if passage else \"\") + w\n",
    "        else:\n",
    "            passage = \" \".join(passage_words)\n",
    "\n",
    "        question = f\"In the above passage, what does \\\"*{original_pronoun}*\\\" refer to?\"\n",
    "\n",
    "        input_str = instructions + \"Passage: \" + passage + \"\\n\" + \\\n",
    "            \"Question: \" + question + \"\\n\" + \\\n",
    "            \"Answer: \" + f\"*{original_pronoun}* refers to \"\n",
    "        \n",
    "        # (dataset, split, example_id, local_context, include_speaker, input, expected_output)\n",
    "        output_example = {\n",
    "            \"dataset\": config_name,\n",
    "            \"split\": split,\n",
    "            \"example_id\": ex_id,\n",
    "            \"local_context\": use_local_context,\n",
    "            \"include_speaker\": include_speaker,\n",
    "            \"input\": input_str,\n",
    "            \"expected_output\": expected_output,\n",
    "            \"negative_output\": negative_output,\n",
    "            \"passage_words\": passage_words,\n",
    "            \"mentions\": mentions,\n",
    "        }\n",
    "        examples.append(output_example)\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1536/1536 [00:06<00:00, 234.07it/s]\n",
      "100%|██████████| 1536/1536 [00:06<00:00, 248.57it/s]\n",
      "100%|██████████| 1536/1536 [00:06<00:00, 233.65it/s]\n",
      "100%|██████████| 1536/1536 [00:06<00:00, 229.72it/s]\n",
      "100%|██████████| 1642/1642 [00:07<00:00, 231.75it/s]\n",
      "100%|██████████| 1642/1642 [00:06<00:00, 248.92it/s]\n",
      "100%|██████████| 1642/1642 [00:07<00:00, 223.33it/s]\n",
      "100%|██████████| 1642/1642 [00:06<00:00, 235.84it/s]\n",
      "100%|██████████| 272/272 [00:02<00:00, 117.93it/s]\n",
      "100%|██████████| 272/272 [00:02<00:00, 119.34it/s]\n",
      "100%|██████████| 272/272 [00:02<00:00, 122.75it/s]\n",
      "100%|██████████| 272/272 [00:02<00:00, 124.93it/s]\n",
      "100%|██████████| 236/236 [00:01<00:00, 121.31it/s]\n",
      "100%|██████████| 236/236 [00:01<00:00, 124.44it/s]\n",
      "100%|██████████| 236/236 [00:01<00:00, 127.47it/s]\n",
      "100%|██████████| 236/236 [00:01<00:00, 128.40it/s]\n",
      "100%|██████████| 179/179 [00:02<00:00, 61.00it/s] \n",
      "100%|██████████| 179/179 [00:02<00:00, 62.49it/s] \n",
      "100%|██████████| 179/179 [00:02<00:00, 60.44it/s] \n",
      "100%|██████████| 179/179 [00:02<00:00, 61.40it/s] \n",
      "100%|██████████| 411/411 [00:04<00:00, 90.04it/s] \n",
      "100%|██████████| 411/411 [00:04<00:00, 96.51it/s] \n",
      "100%|██████████| 411/411 [00:04<00:00, 93.93it/s] \n",
      "100%|██████████| 411/411 [00:04<00:00, 93.69it/s] \n",
      "100%|██████████| 203/203 [00:00<00:00, 751.26it/s]\n",
      "100%|██████████| 203/203 [00:00<00:00, 870.97it/s]\n",
      "100%|██████████| 203/203 [00:00<00:00, 872.24it/s]\n",
      "100%|██████████| 203/203 [00:00<00:00, 869.58it/s]\n",
      "100%|██████████| 832/832 [00:00<00:00, 836.08it/s]\n",
      "100%|██████████| 832/832 [00:00<00:00, 851.96it/s]\n",
      "100%|██████████| 832/832 [00:00<00:00, 885.03it/s]\n",
      "100%|██████████| 832/832 [00:00<00:00, 897.27it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 959.99it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 1505.35it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 1738.32it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 1889.95it/s]\n",
      "100%|██████████| 2167/2167 [00:02<00:00, 853.24it/s]\n",
      "100%|██████████| 2167/2167 [00:02<00:00, 867.18it/s]\n",
      "100%|██████████| 2167/2167 [00:02<00:00, 845.68it/s]\n",
      "100%|██████████| 2167/2167 [00:02<00:00, 831.34it/s]\n",
      "100%|██████████| 2248/2248 [00:02<00:00, 820.73it/s]\n",
      "100%|██████████| 2248/2248 [00:02<00:00, 912.77it/s]\n",
      "100%|██████████| 2248/2248 [00:02<00:00, 796.83it/s]\n",
      "100%|██████████| 2248/2248 [00:02<00:00, 875.51it/s]\n",
      "100%|██████████| 305/305 [00:06<00:00, 45.59it/s]\n",
      "100%|██████████| 305/305 [00:05<00:00, 52.91it/s]\n",
      "100%|██████████| 305/305 [00:05<00:00, 52.06it/s]\n",
      "100%|██████████| 305/305 [00:06<00:00, 49.62it/s]\n",
      "100%|██████████| 254/254 [00:05<00:00, 44.00it/s]\n",
      "100%|██████████| 254/254 [00:04<00:00, 51.49it/s]\n",
      "100%|██████████| 254/254 [00:04<00:00, 50.87it/s]\n",
      "100%|██████████| 254/254 [00:05<00:00, 50.73it/s]\n",
      "100%|██████████| 261/261 [00:02<00:00, 100.44it/s]\n",
      "100%|██████████| 261/261 [00:02<00:00, 124.72it/s]\n",
      "100%|██████████| 261/261 [00:02<00:00, 110.28it/s]\n",
      "100%|██████████| 261/261 [00:02<00:00, 123.04it/s]\n",
      "100%|██████████| 238/238 [00:02<00:00, 104.35it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 126.67it/s]\n",
      "100%|██████████| 238/238 [00:02<00:00, 113.77it/s]\n",
      "100%|██████████| 238/238 [00:01<00:00, 125.39it/s]\n",
      "100%|██████████| 909/909 [00:21<00:00, 42.56it/s] \n",
      "100%|██████████| 909/909 [00:20<00:00, 44.02it/s] \n",
      "100%|██████████| 909/909 [00:24<00:00, 37.62it/s] \n",
      "100%|██████████| 909/909 [00:26<00:00, 34.22it/s] \n",
      "100%|██████████| 338/338 [00:01<00:00, 222.32it/s]\n",
      "100%|██████████| 338/338 [00:01<00:00, 240.96it/s]\n",
      "100%|██████████| 338/338 [00:01<00:00, 222.22it/s]\n",
      "100%|██████████| 338/338 [00:01<00:00, 191.58it/s]\n",
      "100%|██████████| 342/342 [00:01<00:00, 185.27it/s]\n",
      "100%|██████████| 342/342 [00:02<00:00, 168.96it/s]\n",
      "100%|██████████| 342/342 [00:01<00:00, 191.76it/s]\n",
      "100%|██████████| 342/342 [00:02<00:00, 165.77it/s]\n",
      "100%|██████████| 309/309 [00:01<00:00, 290.10it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 323.61it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 314.37it/s]\n",
      "100%|██████████| 309/309 [00:00<00:00, 320.88it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 2239.72it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 3149.00it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 3148.89it/s]\n",
      "100%|██████████| 180/180 [00:00<00:00, 3157.56it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 2119.20it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 3063.82it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 3082.12it/s]\n",
      "100%|██████████| 146/146 [00:00<00:00, 3151.76it/s]\n",
      "100%|██████████| 558/558 [00:00<00:00, 3009.50it/s]\n",
      "100%|██████████| 558/558 [00:00<00:00, 1228.03it/s]\n",
      "100%|██████████| 558/558 [00:00<00:00, 3245.89it/s]\n",
      "100%|██████████| 558/558 [00:00<00:00, 3384.50it/s]\n",
      "100%|██████████| 21240/21240 [00:03<00:00, 6525.57it/s]\n",
      "100%|██████████| 21240/21240 [00:03<00:00, 6162.26it/s]\n",
      "100%|██████████| 21240/21240 [00:03<00:00, 6068.86it/s]\n",
      "100%|██████████| 21240/21240 [00:03<00:00, 6638.01it/s]\n",
      "100%|██████████| 3061/3061 [00:00<00:00, 6118.28it/s]\n",
      "100%|██████████| 3061/3061 [00:00<00:00, 6752.57it/s]\n",
      "100%|██████████| 3061/3061 [00:00<00:00, 6680.26it/s]\n",
      "100%|██████████| 3061/3061 [00:00<00:00, 3513.33it/s]\n",
      "100%|██████████| 209/209 [00:00<00:00, 2402.18it/s]\n",
      "100%|██████████| 209/209 [00:00<00:00, 2682.93it/s]\n",
      "100%|██████████| 209/209 [00:00<00:00, 2678.94it/s]\n",
      "100%|██████████| 209/209 [00:00<00:00, 2703.40it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert all examples to a GPT-3 style input string.\n",
    "\n",
    "(dataset, split, example_id, local_context, include_speaker, input, expected_output)\n",
    "\n",
    "Scored using uncased exact match.\n",
    "\n",
    "Prompt:\n",
    "```\n",
    "Please carefully read the following passages. For each passage, you must identify\n",
    "which noun the mention marked in *bold* refers to.\n",
    "\n",
    "Passage: [Tom] and [Mary] go to [the park]. *It* was full of trees.\n",
    "Question: In the above passage, what does *It* refer to?\n",
    "Answer: *It* refers to [the park]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "def get_all_examples(config_name, split, dataset):\n",
    "    examples = []\n",
    "    for use_local_context, include_speaker in itertools.product([True, False], [True, False]):\n",
    "        examples += get_examples(config_name, split, dataset,\n",
    "                        use_local_context=use_local_context, include_speaker=include_speaker)\n",
    "    return examples\n",
    "\n",
    "\n",
    "def main():\n",
    "    examples = []\n",
    "    for config_name in config_names:\n",
    "        dataset_name = \"coref-data/pcr_single_antecedent\"\n",
    "        dataset = datasets.load_dataset(dataset_name, config_name)\n",
    "        for split in [\"validation\", \"test\"]:\n",
    "            if split not in dataset:\n",
    "                continue\n",
    "            examples += get_all_examples(config_name, split, dataset[split])\n",
    "    return examples\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152436"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please carefully read the following passages. For each passage, you must identify which noun the mention marked in *bold* refers to.\n",
      "\n",
      "Passage: \n",
      "\n",
      "Speaker#1:\n",
      " [The world 's fifth [Disney] park] will soon open to the public here .\n",
      "\n",
      "Zhou_liangshuyi:\n",
      " The most important thing about Disney is that it is a global brand . Well , for several years , although *it* was still under construction and , er , not yet open , it can be said that many people have viewed Hong Kong with new respect .\n",
      "Question: In the above passage, what does \"*it*\" refer to?\n",
      "Answer: *it* refers to \n",
      "********************\n",
      "the world 's fifth disney park\n"
     ]
    }
   ],
   "source": [
    "for d in data[:1]:\n",
    "    print(d[\"input\"])\n",
    "    print(\"*\"*20)\n",
    "    print(d[\"expected_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 153/153 [00:00<00:00, 154.63ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:14<00:00, 14.96s/it]\n",
      "README.md: 100%|██████████| 662/662 [00:00<00:00, 3.38MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/coref-data/pcr_qa_prompt/commit/7037f1ff063c7c7bb2df305acaeddcf06b2b1519', commit_message='Upload dataset', commit_description='', oid='7037f1ff063c7c7bb2df305acaeddcf06b2b1519', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.Dataset.from_list(data)\n",
    "dataset.push_to_hub(\"coref-data/pcr_qa_prompt\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaphora_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
